{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4969047",
   "metadata": {},
   "source": [
    "# Project 2 — NYC Motor Vehicle Collisions Data, NYC Restaurant Inspection Results, NYC 311 Service Requests\n",
    "\n",
    "\n",
    "Datasets (direct URLs):\n",
    "1) **NYC Motor Vehicle Collisions (Crashes)** — CSV endpoint: https://data.cityofnewyork.us/resource/h9gi-nx95.csv  \n",
    "   About page: https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95/about_data\n",
    "2) **NYC Restaurant Inspection Results** → CSV endpoint: https://data.cityofnewyork.us/resource/43nn-pn8j.csv\n",
    "3) **NYC 311 Service Requests** — CSV: https://data.cityofnewyork.us/resource/erm2-nwe9.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae8c9e",
   "metadata": {},
   "source": [
    "## 0) Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc0fea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def melt_except(df, id_cols, var_name, value_name):\n",
    "    return df.melt(id_vars=id_cols, var_name=var_name, value_name=value_name)\n",
    "\n",
    "def wow(curr, prev):\n",
    "    prev = prev.replace(0, np.nan)\n",
    "    return curr/prev - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632334ee",
   "metadata": {},
   "source": [
    "## A) NYC Motor Vehicle Collisions — 2023 slice → Wide pivot → Tidy → Monthly injury analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6351eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "\n",
    "BASE = \"https://data.cityofnewyork.us/resource/h9gi-nx95.csv\"\n",
    "params = {\n",
    "    \"$select\": \"*\",\n",
    "    \"$where\": \"crash_date between '2023-01-01T00:00:00.000' and '2023-12-31T23:59:59.999'\",\n",
    "    \"$order\": \"crash_date DESC\",\n",
    "    \"$limit\": 50000   # Socrata often caps around 50k per call without pagination\n",
    "}\n",
    "\n",
    "url = f\"{BASE}?{urlencode(params)}\"\n",
    "crash = pd.read_csv(url, parse_dates=[\"crash_date\"], low_memory=False)\n",
    "crash.head()\n",
    "cr = crash.copy()\n",
    "cr.columns = cr.columns.str.lower()\n",
    "\n",
    "# make integers\n",
    "for c in [\"persons_injured\",\"persons_killed\",\"pedestrians_injured\",\"pedestrians_killed\",\n",
    "          \"cyclists_injured\",\"cyclists_killed\",\"motorists_injured\",\"motorists_killed\"]:\n",
    "    if c in cr.columns:\n",
    "        cr[c] = pd.to_numeric(cr[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# timestamps\n",
    "cr[\"borough\"] = cr.get(\"borough\", pd.Series(index=cr.index)).astype(\"string\").str.title().fillna(\"Unknown\")\n",
    "cr[\"crash_time\"] = cr.get(\"crash_time\").astype(str).str.zfill(5)\n",
    "cr[\"ts\"] = pd.to_datetime(cr[\"crash_date\"].dt.strftime(\"%Y-%m-%d\") + \" \" + cr[\"crash_time\"], errors=\"coerce\")\n",
    "cr[\"ym\"] = cr[\"ts\"].dt.to_period(\"M\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26d4797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96606, 29)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Tidy back to long and rank boroughs by total injuries in 2023 ---\n",
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "\n",
    "BASE = \"https://data.cityofnewyork.us/resource/h9gi-nx95.csv\"\n",
    "WHERE = \"crash_date between '2023-01-01T00:00:00.000' and '2023-12-31T23:59:59.999'\"\n",
    "\n",
    "frames = []\n",
    "offset = 0\n",
    "LIMIT = 50000\n",
    "\n",
    "while True:\n",
    "    q = {\n",
    "        \"$select\": \"*\",\n",
    "        \"$where\": WHERE,\n",
    "        \"$order\": \"crash_date DESC\",\n",
    "        \"$limit\": LIMIT,\n",
    "        \"$offset\": offset\n",
    "    }\n",
    "    url = f\"{BASE}?{urlencode(q)}\"\n",
    "    chunk = pd.read_csv(url, parse_dates=[\"crash_date\"], low_memory=False)\n",
    "    if chunk.empty:\n",
    "        break\n",
    "    frames.append(chunk)\n",
    "    offset += LIMIT\n",
    "    # (optional) print progress: print(f\"Fetched {offset} rows...\")\n",
    "\n",
    "crash = pd.concat(frames, ignore_index=True)\n",
    "crash.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93b638b9-e44e-47bd-bcb3-bc506768f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly injuries (wide) — last 5 months:\n",
      "borough  Bronx  Brooklyn  Manhattan  Queens  Staten Island  Unknown\n",
      "ym                                                                 \n",
      "2023-08    512      1104        538     823            109     1714\n",
      "2023-09    536      1127        494     838            126     1649\n",
      "2023-10    520      1173        579     955            115     1729\n",
      "2023-11    505      1036        444     832            126     1539\n",
      "2023-12    445      1003        442     859            166     1592\n",
      "\n",
      "Tidy sample:\n",
      "         ym borough  injuries\n",
      "0   2023-01   Bronx       403\n",
      "6   2023-02   Bronx       356\n",
      "12  2023-03   Bronx       444\n",
      "18  2023-04   Bronx       502\n",
      "24  2023-05   Bronx       542\n",
      "\n",
      "Injuries by borough (total + share):\n",
      "               total_injuries_2023  share_%\n",
      "borough                                    \n",
      "Unknown                      19569    36.07\n",
      "Brooklyn                     12376    22.81\n",
      "Queens                        9518    17.54\n",
      "Bronx                         5811    10.71\n",
      "Manhattan                     5612    10.34\n",
      "Staten Island                 1366     2.52\n",
      "\n",
      "Severity proxy (injuries per 100 crashes):\n",
      "               crashes  injuries  injuries_per_100_crashes\n",
      "borough                                                   \n",
      "Unknown          30878     19569                 63.375219\n",
      "Bronx            10507      5811                 55.305986\n",
      "Brooklyn         22890     12376                 54.067278\n",
      "Queens           17786      9518                 53.514000\n",
      "Staten Island     2724      1366                 50.146843\n",
      "Manhattan        11821      5612                 47.474833\n",
      "\n",
      "Seasonality — share of yearly injuries by month (sum = 100%):\n",
      "month\n",
      "1     6.87\n",
      "2     6.52\n",
      "3     7.94\n",
      "4     7.95\n",
      "5     9.22\n",
      "6     8.48\n",
      "7     9.47\n",
      "8     8.85\n",
      "9     8.79\n",
      "10    9.35\n",
      "11    8.26\n",
      "12    8.31\n",
      "Name: share_%, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# assume raw dataframe is named `crash`\n",
    "cr = crash.copy()\n",
    "cr.columns = cr.columns.str.lower()\n",
    "\n",
    "# helper to grab the first column that exists\n",
    "def pick(*names):\n",
    "    for n in names:\n",
    "        if n in cr.columns:\n",
    "            return n\n",
    "    raise KeyError(f\"None of these columns found: {names}\")\n",
    "\n",
    "# map canonical names -> actual column names in df\n",
    "COL = {\n",
    "    \"inj_pers\":  pick(\"number_of_persons_injured\", \"persons_injured\"),\n",
    "    \"kill_pers\": pick(\"number_of_persons_killed\", \"persons_killed\"),\n",
    "    \"inj_ped\":   pick(\"number_of_pedestrians_injured\", \"pedestrians_injured\"),\n",
    "    \"kill_ped\":  pick(\"number_of_pedestrians_killed\", \"pedestrians_killed\"),\n",
    "    \"inj_cyc\":   pick(\"number_of_cyclist_injured\", \"cyclists_injured\", \"number_of_cyclists_injured\"),\n",
    "    \"kill_cyc\":  pick(\"number_of_cyclist_killed\", \"cyclists_killed\", \"number_of_cyclists_killed\"),\n",
    "    \"inj_mot\":   pick(\"number_of_motorist_injured\", \"motorists_injured\"),\n",
    "    \"kill_mot\":  pick(\"number_of_motorist_killed\", \"motorists_killed\"),\n",
    "}\n",
    "\n",
    "# coerce numeric\n",
    "for c in COL.values():\n",
    "    cr[c] = pd.to_numeric(cr[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# borough + timestamp\n",
    "if \"borough\" in cr.columns:\n",
    "    cr[\"borough\"] = cr[\"borough\"].astype(\"string\").str.title().fillna(\"Unknown\")\n",
    "else:\n",
    "    cr[\"borough\"] = \"Unknown\"\n",
    "\n",
    "# build a timestamp from crash_date + crash_time\n",
    "time_col = \"crash_time\" if \"crash_time\" in cr.columns else None\n",
    "date_col = \"crash_date\" if \"crash_date\" in cr.columns else pick(\"crash_date\")\n",
    "\n",
    "if time_col:\n",
    "    cr[time_col] = cr[time_col].astype(str).str.zfill(5)\n",
    "    cr[\"ts\"] = pd.to_datetime(cr[date_col].astype(str).str[:10] + \" \" + cr[time_col], errors=\"coerce\")\n",
    "else:\n",
    "    cr[\"ts\"] = pd.to_datetime(cr[date_col], errors=\"coerce\")\n",
    "\n",
    "# ---- MONTHLY INJURIES (wide pivot: rows = month, cols = borough) ----\n",
    "cr[\"ym\"] = cr[\"ts\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "monthly = (cr.groupby([\"ym\",\"borough\"])[COL[\"inj_pers\"]]\n",
    "             .sum()\n",
    "             .reset_index()\n",
    "             .rename(columns={COL[\"inj_pers\"]: \"persons_injured\"}))\n",
    "\n",
    "wide_inj = (monthly\n",
    "            .pivot(index=\"ym\", columns=\"borough\", values=\"persons_injured\")\n",
    "            .fillna(0).astype(int)\n",
    "            .sort_index())\n",
    "\n",
    "print(\"Monthly injuries (wide) — last 5 months:\")\n",
    "print(wide_inj.tail())\n",
    "\n",
    "# ---- Tidy back (long) ----\n",
    "inj_long = monthly.rename(columns={\"persons_injured\": \"injuries\"}).sort_values([\"borough\",\"ym\"])\n",
    "print(\"\\nTidy sample:\")\n",
    "print(inj_long.head())\n",
    "\n",
    "# ---- Borough totals + share ----\n",
    "boro_tot = (inj_long.groupby(\"borough\")[\"injuries\"].sum()\n",
    "            .sort_values(ascending=False).to_frame(\"total_injuries_2023\"))\n",
    "boro_tot[\"share_%\"] = (100*boro_tot[\"total_injuries_2023\"]/boro_tot[\"total_injuries_2023\"].sum()).round(2)\n",
    "print(\"\\nInjuries by borough (total + share):\")\n",
    "print(boro_tot)\n",
    "\n",
    "# ---- Simple severity proxy: injuries per 100 crashes ----\n",
    "id_col = \"collision_id\" if \"collision_id\" in cr.columns else None\n",
    "by_boro = (cr.groupby(\"borough\")\n",
    "           .agg(crashes=(id_col, \"count\") if id_col else (date_col, \"count\"),\n",
    "                injuries=(COL[\"inj_pers\"], \"sum\")))\n",
    "by_boro[\"injuries_per_100_crashes\"] = 100*by_boro[\"injuries\"]/by_boro[\"crashes\"]\n",
    "print(\"\\nSeverity proxy (injuries per 100 crashes):\")\n",
    "print(by_boro.sort_values(\"injuries_per_100_crashes\", ascending=False))\n",
    "\n",
    "# ---- Seasonality: share of yearly injuries by calendar month ----\n",
    "cr[\"month\"] = cr[\"ts\"].dt.month\n",
    "season = (cr.groupby(\"month\")[COL[\"inj_pers\"]].sum()\n",
    "          .pipe(lambda s: (100*s/s.sum()).round(2))\n",
    "          .rename(\"share_%\"))\n",
    "print(\"\\nSeasonality — share of yearly injuries by month (sum = 100%):\")\n",
    "print(season)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afcd9a5",
   "metadata": {},
   "source": [
    "\n",
    "## B) NYC Restaurant Inspection Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89737116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>grade</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boro</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bronx</th>\n",
       "      <td>2811</td>\n",
       "      <td>706</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brooklyn</th>\n",
       "      <td>7806</td>\n",
       "      <td>1601</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manhattan</th>\n",
       "      <td>11075</td>\n",
       "      <td>1984</td>\n",
       "      <td>1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queens</th>\n",
       "      <td>6632</td>\n",
       "      <td>1384</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staten Island</th>\n",
       "      <td>1084</td>\n",
       "      <td>250</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "grade              A     B     C\n",
       "boro                            \n",
       "Bronx           2811   706   384\n",
       "Brooklyn        7806  1601  1180\n",
       "Manhattan      11075  1984  1547\n",
       "Queens          6632  1384  1490\n",
       "Staten Island   1084   250    96"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = \"https://data.cityofnewyork.us/resource/43nn-pn8j.csv\"\n",
    "\n",
    "# Pull the last full 12 months\n",
    "START = \"2024-01-01T00:00:00.000\"\n",
    "END   = \"2024-12-31T23:59:59.999\"\n",
    "\n",
    "SELECT = \"camis,boro,cuisine_description,grade,grade_date\"\n",
    "WHERE  = f\"grade_date between '{START}' and '{END}' AND grade in ('A','B','C')\"\n",
    "\n",
    "def read_socrata_paged(base, select, where, limit=50000, max_rows=300000):\n",
    "    frames = []\n",
    "    offset = 0\n",
    "    while True:\n",
    "        q = {\n",
    "            \"$select\": select,\n",
    "            \"$where\": where,\n",
    "            \"$limit\": limit,\n",
    "            \"$offset\": offset,\n",
    "            \"$order\": \"grade_date DESC\",\n",
    "        }\n",
    "        url = f\"{base}?{urlencode(q)}\"\n",
    "        chunk = pd.read_csv(url, parse_dates=[\"grade_date\"], low_memory=False)\n",
    "        if chunk.empty:\n",
    "            break\n",
    "        frames.append(chunk)\n",
    "        offset += limit\n",
    "        if offset >= max_rows:\n",
    "            break\n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "ri = read_socrata_paged(BASE, SELECT, WHERE)\n",
    "if ri.empty:\n",
    "    raise ValueError(\"No rows returned. Try a smaller date window or re-run in a few minutes.\")\n",
    "\n",
    "# ---------- Basic cleanup ----------\n",
    "ri.columns = ri.columns.str.lower()\n",
    "ri[\"boro\"] = ri[\"boro\"].fillna(\"UNKNOWN\").str.title()\n",
    "ri[\"cuisine_description\"] = ri[\"cuisine_description\"].fillna(\"Unknown\").str.title()\n",
    "ri[\"grade\"] = ri[\"grade\"].fillna(\"Not Graded\")\n",
    "ri[\"year_month\"] = ri[\"grade_date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# ---------- WIDE: borough × grade counts over the period ----------\n",
    "counts = (ri.groupby([\"boro\",\"grade\"]).size()\n",
    "            .reset_index(name=\"n\"))\n",
    "wide_boro_grade = counts.pivot(index=\"boro\", columns=\"grade\", values=\"n\").fillna(0).astype(int)\n",
    "wide_boro_grade.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e589ed-479e-45c4-aa5f-b6fb4b7b4498",
   "metadata": {},
   "source": [
    "\n",
    "## Citywide totals\n",
    "- **Total graded inspections:** 40,030  \n",
    "- **A:** 29,408 (**73.46%**) · **B:** 5,925 (**14.80%**) · **C:** 4,697 (**11.73%**)\n",
    "\n",
    "## Borough shares (within-borough %)\n",
    "| Borough        | Total | A %    | B %    | C %    |\n",
    "|----------------|-------|--------|--------|--------|\n",
    "| Manhattan      | 14,606| **75.83%** | 13.58% | 10.59% |\n",
    "| Staten Island  | 1,430 | **75.80%** | 17.48% | **6.71%** |\n",
    "| Brooklyn       | 10,587| 73.73% | 15.12% | 11.15% |\n",
    "| Bronx          | 3,901 | 72.06% | **18.10%** | 9.84% |\n",
    "| Queens         | 9,506 | **69.77%** | 14.56% | **15.67%** |\n",
    "\n",
    "## Key takeaways\n",
    "1. **A-rate leaders:** Manhattan and Staten Island (~**75.8% A**).  \n",
    "2. **Queens has elevated C’s:** **15.67% C**, vs citywide **11.73%** (~**1.34×** overall and **1.48×** Manhattan).  \n",
    "3. **B’s are higher in Bronx/Staten Island:** Bronx **18.10%**, Staten Island **17.48%** (Manhattan lowest at **13.58%**).  \n",
    "4. **Statistical signal:** Chi-square test (5 boroughs × 3 grades) yields **χ²(8) ≈ 270.1** ⇒ **grade distributions differ by borough**.\n",
    "\n",
    "## 95% confidence intervals (A-rate)\n",
    "- Manhattan **75.83%** (≈ **75.12–76.51%**)  \n",
    "- Staten Island **75.80%** (≈ **73.52–77.95%**)  \n",
    "- Brooklyn **73.73%** (≈ **72.89–74.56%**)  \n",
    "- Bronx **72.06%** (≈ **70.63–73.44%**)  \n",
    "- Queens **69.77%** (≈ **68.84–70.68%**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9f22f",
   "metadata": {},
   "source": [
    "\n",
    "## C) NYC 311 Service Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84e83869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>borough</th>\n",
       "      <th>year_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-31 23:59:42</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Queens</td>\n",
       "      <td>2023-12-25/2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-31 23:59:39</td>\n",
       "      <td>Noise - Helicopter</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>2023-12-25/2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-31 23:59:29</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Queens</td>\n",
       "      <td>2023-12-25/2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-31 23:59:29</td>\n",
       "      <td>Blocked Driveway</td>\n",
       "      <td>Queens</td>\n",
       "      <td>2023-12-25/2023-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-31 23:59:23</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>2023-12-25/2023-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_date           complaint_type    borough  \\\n",
       "0 2023-12-31 23:59:42  Noise - Street/Sidewalk     Queens   \n",
       "1 2023-12-31 23:59:39       Noise - Helicopter  Manhattan   \n",
       "2 2023-12-31 23:59:29  Noise - Street/Sidewalk     Queens   \n",
       "3 2023-12-31 23:59:29         Blocked Driveway     Queens   \n",
       "4 2023-12-31 23:59:23  Noise - Street/Sidewalk   Brooklyn   \n",
       "\n",
       "               year_week  \n",
       "0  2023-12-25/2023-12-31  \n",
       "1  2023-12-25/2023-12-31  \n",
       "2  2023-12-25/2023-12-31  \n",
       "3  2023-12-25/2023-12-31  \n",
       "4  2023-12-25/2023-12-31  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "\n",
    "def socrata_read_csv(base, select, where=None, order=None, app_token=None,\n",
    "                     limit=50000, max_pages=20, parse_dates=None):\n",
    "    frames, offset = [], 0\n",
    "    for _ in range(max_pages):\n",
    "        q = {\"$select\": select, \"$limit\": limit, \"$offset\": offset}\n",
    "        if where: q[\"$where\"] = where\n",
    "        if order: q[\"$order\"] = order\n",
    "        if app_token: q[\"$$app_token\"] = app_token  # header also works, but query param is fine\n",
    "        url = f\"{base}?{urlencode(q)}\"\n",
    "        chunk = pd.read_csv(url, parse_dates=parse_dates, low_memory=False)\n",
    "        if chunk.empty:\n",
    "            break\n",
    "        frames.append(chunk)\n",
    "        offset += limit\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "URL_311 = \"https://data.cityofnewyork.us/resource/erm2-nwe9.csv\"\n",
    "SELECT = \"created_date, complaint_type, borough\"\n",
    "WHERE  = \"created_date between '2023-01-01T00:00:00.000' and '2023-12-31T23:59:59.999'\"\n",
    "ORDER  = \"created_date DESC\"\n",
    "\n",
    "sr = socrata_read_csv(URL_311, SELECT, WHERE, ORDER, app_token=None,\n",
    "                      limit=50000, max_pages=10, parse_dates=[\"created_date\"])\n",
    "\n",
    "# cleanup\n",
    "sr.columns = sr.columns.str.lower()\n",
    "sr[\"complaint_type\"] = sr[\"complaint_type\"].astype(\"string\").str.strip()\n",
    "sr[\"borough\"] = sr[\"borough\"].astype(\"string\").str.title()\n",
    "sr[\"year_week\"] = sr[\"created_date\"].dt.to_period(\"W\").astype(str)\n",
    "sr.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc48f7-ad65-4550-adf3-ba9af1d135e4",
   "metadata": {},
   "source": [
    "## Each row is a 311 request with a timestamp (created_date), a category (complaint_type), and a location summary (borough). Below are a few example records from the very end of 2023 (Dec 25–Dec 31):\n",
    " # |----------------------|--------------------------|------------|-----------------------|\n",
    "    |created_date          | complaint_type           | borough    | year_week |\n",
    "    |2023-12-31 23:59:42   | Noise - Street/Sidewalk  | Queens     | 2023-12-25/2023-12-31 |\n",
    "    |2023-12-31 23:59:39   | Noise - Helicopter       | Manhattan  | 2023-12-25/2023-12-31 |\n",
    "    |2023-12-31 23:59:29   | Noise - Street/Sidewalk  | Queens     | 2023-12-25/2023-12-31 |\n",
    "    |2023-12-31 23:59:29   | Blocked Driveway         | Queens     | 2023-12-25/2023-12-31 |\n",
    "    |2023-12-31 23:59:23   | Noise - Street/Sidewalk  | Brooklyn   | 2023-12-25/2023-12-31 |\n",
    "\n",
    " These rows already hint at a well-known pattern: Noise complaints dominate the late-evening periods, especially around weekends and holidays.\n",
    "\n",
    "## Key findings\n",
    "1) Top complaint types\n",
    "Noise categories (e.g., Noise – Street/Sidewalk, Noise – Neighbor, Noise – Helicopter) are the most frequent across the year.\n",
    "Non-noise but consistently high categories include Blocked Driveway, Illegal Parking, and Sanitation complaints (e.g., Dirty Conditions).\n",
    "Why it matters: noise and parking/sanitation drive a large share of NYC 311 volume, tracking them week-over-week gives a sensitive measure of neighborhood quality-of-life issues.\n",
    "\n",
    "2) Borough mix\n",
    "Absolute volumes are typically highest in Brooklyn and Manhattan, followed by Queens; Bronx and Staten Island are smaller in absolute counts (population & land-use effects).\n",
    "The share of certain complaint types differs by borough. For example, helicopter noise skews toward Manhattan, while Blocked Driveway is more common in lower-density/driveway-heavy areas.\n",
    "Why it matters: comparisons should use rates or shares, not just counts, to avoid confusing population/land-use with complaint intensity.\n",
    "\n",
    "3) Weekly trends (Top 5 categories)\n",
    "Weekly time series for the overall top-5 complaints show a stable baseline plus spikes aligned to holidays/events and seasonal patterns.\n",
    "Noise complaints tend to rise on weekends and during late-evening hours; sanitation and parking can vary with weather and street activity.\n",
    "Analyst note: a 4-week rolling mean helps separate noise from weekly noise.\n",
    "\n",
    "4) Noise share by borough\n",
    "Computing Noise_share = Noise_requests / All_requests by borough reveals which areas have a disproportionate quality-of-life concern around sound.\n",
    "Dense mixed-use districts (nightlife, tourism, heli routes) tend to have higher noise shares, while residential/auto-oriented areas show relatively higher parking/driveway issues.\n",
    "\n",
    "5) Hour-of-day profile\n",
    "Noise requests peak in evening and late-night hours (exact top hour varies by borough).\n",
    "Parking/driveway and sanitation items often peak in daytime.\n",
    "Takeaway: the hourly shape by category is a quick diagnostic—if Noise peaks shift later/earlier across weeks, that can flag policy or enforcement changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ad77c-2e84-442b-84fb-246ab996ce32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
